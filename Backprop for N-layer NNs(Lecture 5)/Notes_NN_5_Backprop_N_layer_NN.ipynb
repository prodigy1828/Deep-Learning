{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "\n",
        "- **Backpropagation in N layered NN**"
      ],
      "metadata": {
        "id": "l6cXr7mFjjZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZLYwdCpdgNYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1dLOPwh01o3k8p_hK633ixhD1ehz6nNWk\n",
        "df = pd.read_csv(\"/content/spiral.csv\")\n",
        "\n",
        "# Separating feature and label columns\n",
        "X = df.iloc[:, :-1].to_numpy()\n",
        "y = df.iloc[:, -1].to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2DwJZ28gJxB",
        "outputId": "e7b31f87-a064-4c5f-e619-30a2326ca47c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dLOPwh01o3k8p_hK633ixhD1ehz6nNWk\n",
            "To: /content/spiral.csv\n",
            "\r  0% 0.00/12.9k [00:00<?, ?B/s]\r100% 12.9k/12.9k [00:00<00:00, 14.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's get back to our NN network"
      ],
      "metadata": {
        "id": "KVfSGd_aHqlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1PWWndBIY0xFSxY7E06DEoTH9-JNuZryf' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "bkjAr2U6Hyh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How'll computational graph look for above NN ?"
      ],
      "metadata": {
        "id": "TbKCU6nAIKsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1AN7oW_aSWmGb8PeQS8xtlytsqI0YZUUT' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "8P8sGIHoIU44"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NenozJcZrEWE"
      },
      "source": [
        "### Forward Propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to calculate Z1,\n",
        "- for this we multiply each row of X with each column of W1\n",
        "- add bias to it (using broadcasting)\n",
        "\n",
        "\n",
        "The formulation comes out to be:\n",
        "\n",
        "$$X.W + b$$"
      ],
      "metadata": {
        "id": "JnXJolbZt133"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# initialize parameters randomly\n",
        "d = 2 # diensionality / number of inputs\n",
        "n = 3 # Number of classes (A/B/C) / Number of neurons in output layer\n",
        "h = 4 # neurons in hidden layer"
      ],
      "metadata": {
        "id": "UpSGuRU0y5oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let;s intitialise these matrices randomly."
      ],
      "metadata": {
        "id": "IHJReVDzyzwv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCY9Gn0lrEWE"
      },
      "outputs": [],
      "source": [
        "W1 = 0.01 * np.random.randn(d,h)\n",
        "b1 = np.zeros((1,h))\n",
        "W2 = 0.01 * np.random.randn(h,n)\n",
        "b2 = np.zeros((1,n))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2faLFmnrEWE"
      },
      "outputs": [],
      "source": [
        "Z1 = np.dot(X, W1) + b1 # (300,2) x (2,4) + (1,4) => (300,4)\n",
        "A1 = np.maximum(0, Z1) # ReLU if Z1 < 0 A1 =0 else A1 = Z1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculation Z2 and A2"
      ],
      "metadata": {
        "id": "u57B3T81uOXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, in order to get shape of (300,3)\n",
        "- we need to multiply $A_1$ with $W^2$ and add bias $b^2$ to it\n"
      ],
      "metadata": {
        "id": "sBMxydYkx0p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z2 = np.dot(A1, W2) + b2  # (300, 4) x (4, 3) + (1, 3) => (300, 3)\n",
        "# Applying softmax function to get A2\n",
        "Z2_exp = np.exp(Z2)\n",
        "A2 = Z2_exp/np.sum(Z2_exp, axis=1, keepdims=True)\n",
        "probs = A2"
      ],
      "metadata": {
        "id": "d8hQfcg7e8Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC1h07UxrEWE"
      },
      "source": [
        "- Notice that the only change from before is one extra line of code.\n",
        "- We first compute the hidden layer representation and considered that as an input to the output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1DQslNtKXMEvwHd5xCplRiiORyEEIIugt' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "QOcmp1F8L-7f"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLLKODN9rEWE"
      },
      "source": [
        "### Loss\n",
        "\n",
        "#### Question: Will the loss change?\n",
        "\n",
        "No\n",
        "\n",
        "### Backpropagation\n",
        "\n",
        "#### Will the gradient calculation change?\n",
        "\n",
        "No, but, we would have to backpropagate the gradients for one additional layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djjOv187rEWE"
      },
      "outputs": [],
      "source": [
        "# Number of training examples\n",
        "m = y.shape[0] # 300 datapoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating dz2"
      ],
      "metadata": {
        "id": "KVq2uZLip5t1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1F8bmELjo3Wb4gOltpB1dsditiw68E9wo' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "m5MxEogZcIMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$dZ_2 = \\frac{∂L}{∂Z_2}$$\n",
        "\n",
        "\n",
        "So,\n",
        "\n",
        "$$\\frac{∂L}{∂Z_2} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}$$\n",
        "\n",
        "Here, $A_2$ is our output probabilities.\n",
        "- Replaceing $A_2$ with $p$\n",
        "\n",
        "$$\\frac{∂L}{∂Z_2} = \\frac{∂L}{∂p}.\\frac{∂p}{∂Z_2}$$\n",
        "\n",
        "#### Doesn't this look familiar ?\n",
        "\n",
        "- This is similar to what we calculated previously i.e derivative of Loss w.r.t to Z\n",
        "\n",
        "$$dz=\\frac{\\partial J}{\\partial p} \\frac{\\partial p}{\\partial z}$$\n",
        "\n",
        "- The derivative came out to be : $dz = (p_i - I (i=y))$\n",
        "\n",
        "\n",
        "Hence, $dZ_2 = (p_i - I (i=y))$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lNpgXmNpp83F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dZ2 = probs\n",
        "dZ2[range(m),y] -= 1"
      ],
      "metadata": {
        "id": "FE0y547c5JB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What will be the shape of dZ2 ?"
      ],
      "metadata": {
        "id": "vAA8ofaUysdB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As dZ2 is same as probabilties,\n",
        "- its shape will be (m,3) or (300, 3)"
      ],
      "metadata": {
        "id": "ZXfBit3PzAKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating $dW^2$ and $db^2$"
      ],
      "metadata": {
        "id": "Xjyuvgfmr1in"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCwJ4_MPrEWF"
      },
      "source": [
        "Gradient calculation for $dW^2$ and $db^2$ will also be similar to $dW$ and $db$ in the softmax classifier case"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1pyy0nm9bRONADdWGYmEJCtC3Y7gRiWTJ' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "XhaSXlTRtISQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$dW_2 = \\frac{∂L}{∂W^2} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂W^2}$$\n",
        "\n",
        "$$= dZ_2.\\frac{∂Z_2}{∂W^2}$$\n",
        "\n",
        "Here, $Z_2 = W^{2^{T}}.A_1 + b^2$\n",
        "\n",
        "So, $\\frac{∂Z_2}{∂W^2} = A_1$\n",
        "\n",
        "$$dW_2 = \\frac{∂L}{∂W^2} = dZ_2 . A_1$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCQ1g0TmuBcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How to do mat mul for dW2  ?"
      ],
      "metadata": {
        "id": "9x68P15mzLRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Shape of dZ2 = (300, 3)\n",
        "- Shape of A1 = (300, 4)\n",
        "\n",
        "#### What should be the shape of dW2 ?\n",
        "\n",
        "We know that dW2 will be used for updating $W^2$\n",
        "- its shape should match of $W^2$\n",
        "\n",
        "Hence, shape of dW2 will be (4,3)\n",
        "\n"
      ],
      "metadata": {
        "id": "_FVVYHZ81R61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to multipy dZ2 and A1\n",
        "- such that we get (4,3)\n",
        "\n",
        "For that, we take a transpose of A1 and multiply it with dW2.\n",
        "\n",
        "=> $A_1^T. dZ_2$ = (4, 300) x (300, 3) = (4, 3)"
      ],
      "metadata": {
        "id": "XR0kiHkg1lnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1JE6a4iXmFJO_Uno_OlUdccZ6hSMT4mGi' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "95N-MebY1Nwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjY5p67hrEWF"
      },
      "outputs": [],
      "source": [
        "# shape A1 => (300,4)  shape dZ2 (equal to probability)=> (300,3)\n",
        "dW2 = np.dot(A1.T, dZ2)/m # shape => (4, 300) x (300, 3) => (4,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### But, why are we dividing by m ?"
      ],
      "metadata": {
        "id": "sumY4y07_P4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that in GD,\n",
        "- as we are using all datapoints for calculating the updated w\n",
        "    - we take average of it by dividing it by total number of datapoints"
      ],
      "metadata": {
        "id": "gY04HPvNAPy2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1d-Oqw5zbGhS3zin_mnycATtK3hOsPDvd' width=\"700\"></center>\n"
      ],
      "metadata": {
        "id": "zGWGgqoP_YEB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Where all do we need to divide by m ?\n",
        "$ $\n",
        "Our goal is to update weights and biases\n",
        "- so we can either do with while calculating the derivates dW2, db2, dW1, db1 (like we are doing)\n",
        "- or we can do it when updating the weights\n",
        "    - i.e. $w^1 = w^1 - η.dw^1.\\frac{1}{m}$"
      ],
      "metadata": {
        "id": "QYpJ9nz9Aelv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we calculate db2"
      ],
      "metadata": {
        "id": "TAmY_3VXt6EL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1DWakdq7pybp7cn8kyfM_P8Dfr2XSHWe2' width=\"700\"></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gcoDFQG-wxO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$db_2 = \\frac{∂L}{∂b^2} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂b^2}$$\n",
        "\n",
        "Now,\n",
        "\n",
        "$$\\frac{∂Z_2}{∂b^2} = \\frac{∂(W^2A_1 + b^2)}{db^2} = 1$$\n",
        "\n",
        "$$db_2 = \\frac{∂L}{∂b^2} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.1 = dZ_2$$\n"
      ],
      "metadata": {
        "id": "Dxg9EqXZw_2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question:  What will be the shape of db2 ?"
      ],
      "metadata": {
        "id": "7fFf3o9T2IP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that db2 will be used to update $b^2$\n",
        "- so their shape should match\n",
        "\n",
        "Hence, Shape of db2 = (1,3)"
      ],
      "metadata": {
        "id": "BP8lb9EWaMGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But, dZ2 shape is (300, 3)\n",
        "\n",
        "Now, recall that we are doing GD not SGD.\n",
        "- we need to sum up the derivates across across the rows and then average it out before using it for update\n"
      ],
      "metadata": {
        "id": "u47nIfTPaU4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1ES5B4mTwP6hhAbo1-EZaMkaF4bupg06M' width=\"700\"></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cU9N4RDb43pH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- So, we'll take the sum across the row"
      ],
      "metadata": {
        "id": "p_3GhI9rapWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db2 = np.sum(dZ2, axis=0, keepdims=True)/m # shape (1 ,3)"
      ],
      "metadata": {
        "id": "BMAJYaUUt5ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkFcUS5crEWF"
      },
      "source": [
        "However, unlike earlier, we are not done yet, because $A_2$ is also a function of $Z_1$, and indirectly of ($W^1$ and $b^1$)\n",
        "- We still need to calculate $dW^1$ and $db^1$\n",
        "- So, we would need to calculate $dZ_1$, followed by $dW^1$ and $dW^2$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating $dA_1$"
      ],
      "metadata": {
        "id": "0YJ6aidmx8Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=13n_WJ9wkWALTdUcrKfD_hCRf6yQt81B1' width=\"700\"></center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EmTimJIhytPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$dA_1 = \\frac{∂L}{∂A_1} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}$$\n",
        "\n",
        "\n",
        "We know that, $$\\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2} = dZ_2$$\n",
        "\n",
        "Now,\n",
        "\n",
        "$$\\frac{∂Z_2}{∂A_1} = \\frac{∂(W^2A_1 + b^2)}{dA_1} = W^2$$\n",
        "\n",
        "\n",
        "$$dA_1 =\\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.W^2 = dZ_2.W^2$$\n"
      ],
      "metadata": {
        "id": "Zl0fOfJUzwQ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1zbsHvM-7MmCQt_1cp2gfs_lWt7d5zYSS' width=\"700\"></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aFKda7I579ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What will be the shape of dA1?\n",
        "\n"
      ],
      "metadata": {
        "id": "w3KWLcxQ5oGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1Wd-6VK4FV7FcCpEu0IvHre0DTMAcBYoD' width=\"700\"></center>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dEY9M9dK78HX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shape of dA1 will be same as dZ1\n",
        "- as A1 is ReLU on top of Z1\n",
        "\n"
      ],
      "metadata": {
        "id": "9zsyIVge8K6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What will be the shape of dZ1 ?\n",
        "- we can calculate it using dW1\n",
        "\n",
        "We know, $$dW^1 = dZ_1.X$$\n",
        "\n",
        "Here,\n",
        "- shape of dW1 = (2,4) i.e. same as W^1\n",
        "- shape of X = (300, 2)\n",
        "\n",
        "Now, in order to get (2,4),\n",
        "- we'll need to take transpose of X (2, 300)\n",
        "- and multiply it by $dZ^1$\n",
        "\n",
        "So, shape of dZ1 will be (300, 4)\n",
        "- Hence, shape of $dA_1$ will be (300, 4)"
      ],
      "metadata": {
        "id": "XlwMMVIVazKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What will be the matrix multiplication  then?"
      ],
      "metadata": {
        "id": "hT9namcB9L1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1VYZS8hjBj0m8K6V3GvIHPN7krAx8qRsR' width=\"700\"></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WrUBKHlP9vzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that, we have all the shapes\n",
        "- dZ2 = (300, 3)\n",
        "- $W^2$ = (4,3)\n",
        "\n",
        "We need a final shape of (300, 4)\n",
        "\n",
        "So, we will have to\n",
        "- multiply dZ2 with transpose of $W^2$\n",
        "- (300, 3) x (3, 4) => (300, 4)\n",
        "\n",
        "$$dA_1 = dZ_2.W^{2^{T}}$$"
      ],
      "metadata": {
        "id": "CxWtG2Q19RTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_fc6GDrEWF"
      },
      "outputs": [],
      "source": [
        "dA1 = np.dot(dZ2, W2.T) # (300,3) x (3 , 4) => (300, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating $dZ_1$"
      ],
      "metadata": {
        "id": "_YXNa9Px0sXd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62HBVo7xrEWF"
      },
      "source": [
        " Now, we have to pass back through the ReLU layer to calculate the gradient $dZ_1$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1vmbFE7xwHaNE4TusswmoZlWrlW8zCZsD' width=\"700\"></center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lryS3eDq1Zm4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\frac{∂L}{∂Z_1} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}.\\frac{∂A_1}{∂Z_1}$$\n",
        "\n",
        "We know that,\n",
        "\n",
        "$$\\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1} = dA_1 $$\n",
        "\n",
        "\n",
        "We have to calculate $\\frac{∂A_1}{∂Z_1}$"
      ],
      "metadata": {
        "id": "yCCb5lqU3QRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1a6fEWOVciKR6YOe5GIbrXtfGNQj9f4Zh' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "dBj0T6DN5cRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1tjieJQH7V3_qkaZRHSu-2iqTmEEk9dIC' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "n-eKtKlq6Dzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyCkJcxRrEWF"
      },
      "outputs": [],
      "source": [
        "dA1[Z1 <= 0] = 0 # was dA1[A1 <= 0] = 0. changed it to dA1[Z1 <= 0] = 0\n",
        "dZ1 = dA1 # same shape as dA1 (300, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### But, why are we updating dA1 and not making a copy of it?\n",
        "\n",
        "Ans: The purpose of calculating dA1 and dZ1 is to ultimately calculate dW1 and db1.\n",
        "\n",
        "These are being used for intermediatory purpose.\n",
        "\n",
        "So, making changes in dA1 won't change anything as\n",
        "- we have already calculated dZ1\n",
        "- and we won't be using dA1 anywhere else except for calc. of dZ1"
      ],
      "metadata": {
        "id": "YVUhW7FHgXYo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiqY9XlQrEWG"
      },
      "source": [
        "This also means that we need to save the intermediate output values from the forward pass.\n",
        "\n",
        "Finally, $dW^1$ and $db^1$ are calculated the same way we did earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating $dW^1$ and $db^1$"
      ],
      "metadata": {
        "id": "3LFF0PybAePt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1grv9nsgIxDgxls2GUD3X11maRnThiULU' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "LLIesEgw9DIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=15cxgjprVngsg35-dowXZ8aeN3-HitX8F' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "Do9ZfbuJ-3V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\frac{∂L}{∂W^1} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}.\\frac{∂A_1}{∂Z_1}.\\frac{∂Z_1}{∂W^1}$$\n",
        "\n",
        "We know that,\n",
        "\n",
        "$$\\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}.\\frac{∂Z_1}{∂A_1} = dZ_1 $$\n",
        "\n",
        "\n",
        "We have to calculate $\\frac{∂Z_1}{∂W^1}$\n",
        "\n",
        "$$\\frac{∂Z_1}{∂W^1} = \\frac{∂(W^1.X + b^1)}{∂W^1} = X $$\n",
        "\n",
        "\n",
        "So,\n",
        "\n",
        "$$ \\frac{∂L}{∂W^1} = dZ_1.X$$"
      ],
      "metadata": {
        "id": "0mRg94aC-2DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, for $db^1$"
      ],
      "metadata": {
        "id": "bA6kxrXi-9Yk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1Hz3jZr-HD-GmgOYu58DBn-CWCSisIF69' width=\"700\"></center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hlLgXqWJAlGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\frac{∂L}{∂b^1} = \\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}.\\frac{∂A_1}{∂Z_1}.\\frac{∂Z_1}{∂b^1}$$\n",
        "\n",
        "We know that,\n",
        "\n",
        "$$\\frac{∂L}{∂A_2}.\\frac{∂A_2}{∂Z_2}.\\frac{∂Z_2}{∂A_1}.\\frac{∂Z_1}{∂A_1} = dZ_1 $$\n",
        "\n",
        "\n",
        "We have to calculate $\\frac{∂Z_1}{∂b^1}$\n",
        "\n",
        "$$\\frac{∂Z_1}{∂b^1} = \\frac{∂(W^1.X + b^1)}{∂b^1} = 1 $$\n",
        "\n",
        "\n",
        "So,\n",
        "\n",
        "$$ \\frac{∂L}{∂b^1} = dZ_1.1$$"
      ],
      "metadata": {
        "id": "RyDoutBHA6hp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cjju4gURrEWG"
      },
      "outputs": [],
      "source": [
        "dW1 = np.dot(X.T, dZ1)/m # (2, 300) x (300 ,4) => (2, 4)\n",
        "db1 = np.sum(dZ1, axis=0, keepdims=True)/m"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've found these gradients, we update the weight and bias values as:-\n"
      ],
      "metadata": {
        "id": "-TxOQ2KE7uTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-0"
      ],
      "metadata": {
        "id": "DROjJjp16mEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform a parameter update\n",
        "W1 += -lr * dW1\n",
        "b1 += -lr * db1\n",
        "W2 += -lr * dW2\n",
        "b2 += -lr * db2"
      ],
      "metadata": {
        "id": "0dqRYm0472sQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This parameter updation is done untill it converges (error goes down)."
      ],
      "metadata": {
        "id": "-poceGqg8DIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summarizing whole process"
      ],
      "metadata": {
        "id": "zumaZQ8xSIkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A single GD cycle for weight update looks like following :"
      ],
      "metadata": {
        "id": "07kHYWpqYioI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1NLwEygpmxSqUbJJQJCb8xdFNJYELa2Ur' width=\"700\"></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7KuROszgR5dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write all the derivatives"
      ],
      "metadata": {
        "id": "iiKhmBIKSPiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1JXuVt7j_BykkF9pKN0z-1Lc9zjO4V8l-' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "EqWO9qhHRzq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that,\n",
        "- We use dZ2 for calculation of dW2, db2 and dA1.\n",
        "- similarly, we use dA1 for calculation of dZ1.\n",
        "- and dZ1 for calculation of dW1 and db1."
      ],
      "metadata": {
        "id": "trW6kaFfSd8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, in order to not calculate value of deeper derivaties i.e dA1, dZ1 again and again\n",
        "- we calculate and store the derivatives of deeper layer\n",
        "- so as we can use them to calculate derivative of shallow layers\n",
        "\n",
        "This is called as **memoization**\n",
        "- also used in **dynamic programming**"
      ],
      "metadata": {
        "id": "9rm0ZvgYS1_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Simplfying the single cycle of updation"
      ],
      "metadata": {
        "id": "RGStIXhXZKZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src='https://drive.google.com/uc?id=1_1GnlUchtfVNFzf1suRhowbnBrkzohmh' width=\"700\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "oU8lcUtGWrTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While performing forward prop,\n",
        "- we store/cache the value of $Z_j, W^j, b^j$ in order to use them during back prop\n",
        "- For example: dA1 uses $w^2$ for its calculation."
      ],
      "metadata": {
        "id": "e8uzmQuUYyim"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-nWDh_IrEWG"
      },
      "source": [
        "Done! Let's put everything together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCaMRBxKrEWG",
        "outputId": "dc8fddb2-37e5-465e-f8c0-c7e3f27c34b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 1.098502\n",
            "iteration 1000: loss 0.323320\n",
            "iteration 2000: loss 0.261405\n",
            "iteration 3000: loss 0.255624\n",
            "iteration 4000: loss 0.253868\n",
            "iteration 5000: loss 0.252423\n",
            "iteration 6000: loss 0.251553\n",
            "iteration 7000: loss 0.250943\n",
            "iteration 8000: loss 0.250460\n",
            "iteration 9000: loss 0.250189\n"
          ]
        }
      ],
      "source": [
        "# initialize parameters randomly\n",
        "d = 2\n",
        "h = 100 # size of hidden layer\n",
        "n = 3\n",
        "W1 = 0.01 * np.random.randn(d,h)\n",
        "b1 = np.zeros((1,h))\n",
        "W2 = 0.01 * np.random.randn(h,n)\n",
        "b2 = np.zeros((1,n))\n",
        "\n",
        "# some hyperparameters\n",
        "lr = 1e-0\n",
        "reg = 1e-3 # regularization strength\n",
        "num_examples = X.shape[0]\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "    # forward prop\n",
        "    Z1 = np.dot(X, W1) + b1\n",
        "    A1 = np.maximum(0, Z1)\n",
        "    Z2 = np.dot(A1, W2) + b2\n",
        "    Z2 = np.exp(Z2)\n",
        "    A2 = Z2 / np.sum(Z2, axis=1, keepdims=True)\n",
        "    probs = A2\n",
        "\n",
        "    # calc. loss\n",
        "    correct_logprobs = -np.log(probs[range(num_examples),y])\n",
        "    data_loss = np.sum(correct_logprobs)/num_examples\n",
        "    reg_loss = 0.5*reg*np.sum(W1*W1) + 0.5*reg*np.sum(W2*W2) # regularization\n",
        "    loss = data_loss + reg_loss # adding reg. to loss\n",
        "    if i % 1000 == 0:\n",
        "        print(\"iteration %d: loss %f\" % (i, loss))\n",
        "\n",
        "    # backprop\n",
        "    # compute the gradient on scores\n",
        "    dZ2 = probs\n",
        "    dZ2[range(num_examples),y] -= 1\n",
        "    dZ2 /= num_examples\n",
        "\n",
        "    # first backprop into parameters W2 and b2\n",
        "    dW2 = np.dot(A1.T, dZ2)\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "    # next backprop into hidden layer, A1\n",
        "    dA1 = np.dot(dZ2, W2.T)\n",
        "    # backprop the ReLU non-linearity\n",
        "    dA1[Z1 <= 0] = 0\n",
        "    # finally into W,b\n",
        "    dZ1 = dA1\n",
        "    dW1 = np.dot(X.T, dZ1)\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "    # add regularization gradient contribution\n",
        "    dW2 += reg * W2\n",
        "    dW1 += reg * W1\n",
        "\n",
        "    # perform a parameter update\n",
        "    W1 += -lr * dW1\n",
        "    b1 += -lr * db1\n",
        "    W2 += -lr * dW2\n",
        "    b2 += -lr * db2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhEtzZUHrEWH"
      },
      "source": [
        "#### NN class - all code wrapped as class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04v7YLXurEWH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c43f84d-971d-4197-d495-c193930a995d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration 0: loss 1.098640\n",
            "iteration 1000: loss 0.319168\n",
            "iteration 2000: loss 0.253549\n",
            "iteration 3000: loss 0.249735\n",
            "iteration 4000: loss 0.248432\n",
            "iteration 5000: loss 0.247951\n",
            "iteration 6000: loss 0.247623\n",
            "iteration 7000: loss 0.247415\n",
            "iteration 8000: loss 0.247351\n",
            "iteration 9000: loss 0.247299\n",
            "training accuracy: 0.99\n"
          ]
        }
      ],
      "source": [
        "class NN:\n",
        "\n",
        "    def __init__(self, n_features, n_hidden, n_classes):\n",
        "        self.d = n_features\n",
        "        self.h = n_hidden\n",
        "        self.n = n_classes\n",
        "        self.W1 = 0.01 * np.random.randn(self.d, self.h)\n",
        "        self.b1 = np.zeros((1,self.h))\n",
        "        self.W2 = 0.01 * np.random.randn(self.h,self.n)\n",
        "        self.b2 = np.zeros((1,self.n))\n",
        "\n",
        "    def fwd_prop(self, X):\n",
        "        Z1 = np.dot(X, self.W1) + self.b1\n",
        "        A1 = np.maximum(0, Z1)\n",
        "        Z2 = np.dot(A1, self.W2) + self.b2\n",
        "        Z2 = np.exp(Z2)\n",
        "        A2 = Z2 / np.sum(Z2, axis=1, keepdims=True)\n",
        "        return A1, A2\n",
        "\n",
        "    def cce_loss(self, y, probs):\n",
        "        num_examples = y.shape[0]\n",
        "        correct_logprobs = -np.log(probs[range(num_examples),y])\n",
        "        loss = np.sum(correct_logprobs)/num_examples\n",
        "        return loss\n",
        "\n",
        "    def back_prop(self, X, A1, A2, y):\n",
        "        # compute the gradient on scores\n",
        "        num_examples = y.shape[0]\n",
        "        dZ2 = A2\n",
        "        dZ2[range(num_examples),y] -= 1\n",
        "        dZ2 /= num_examples\n",
        "        # first backprop into parameters W2 and b2\n",
        "        dW2 = np.dot(A1.T, dZ2)\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "        # next backprop into hidden layer, A1\n",
        "        dA1 = np.dot(dZ2, self.W2.T)\n",
        "        # backprop the ReLU non-linearity\n",
        "        dA1[A1 <= 0] = 0\n",
        "        # finally into W,b\n",
        "        dZ1 = dA1\n",
        "        dW1 = np.dot(X.T, dZ1)\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "        return dW1, db1, dW2, db2\n",
        "\n",
        "    def fit(self, X, lr, reg, max_iters):\n",
        "        num_examples = X.shape[0]\n",
        "        for i in range(max_iters):\n",
        "            #foward prop\n",
        "            A1, A2 = self.fwd_prop(X)\n",
        "            # calculate loss\n",
        "            data_loss = self.cce_loss(y, A2)\n",
        "            reg_loss = 0.5*reg*np.sum(self.W1*self.W1) + 0.5*reg*np.sum(self.W2*self.W2)\n",
        "            loss = data_loss + reg_loss\n",
        "\n",
        "            if i % 1000 == 0:\n",
        "                print(\"iteration %d: loss %f\" % (i, loss))\n",
        "\n",
        "            dW1, db1, dW2, db2  = self.back_prop(X, A1, A2, y)\n",
        "\n",
        "            # add regularization gradient contribution\n",
        "            dW2 += reg * self.W2\n",
        "            dW1 += reg * self.W1\n",
        "\n",
        "            # perform a parameter update\n",
        "            self.W1 += -lr * dW1\n",
        "            self.b1 += -lr * db1\n",
        "            self.W2 += -lr * dW2\n",
        "            self.b2 += -lr * db2\n",
        "\n",
        "    def predict(self, X):\n",
        "        A1 = np.maximum(0, np.dot(X, self.W1) + self.b1) # ReLU(Z1) = ReLU(W1T. X + b1)\n",
        "        Z2 = np.dot(A1, self.W2) + self.b2 # Z2 = W2T.A1 + b2 => 3 probab\n",
        "        y_hat = np.argmax(Z2, axis=1) # taking index of max probab\n",
        "        return y_hat\n",
        "\n",
        "nn_model = NN(n_features=2, n_hidden=100, n_classes=3)\n",
        "nn_model.fit(X, lr=1, reg=1e-3, max_iters=10000)\n",
        "print('training accuracy: %.2f' % (np.mean(nn_model.predict(X) == y)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "u_4VUY4OBtvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCXe-zVirEWH",
        "outputId": "e30dc123-201d-4c2e-b3c2-163d35890884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29eZCk91nn+XneN6+6776qu9Vqdeu2zrawbBa3gRHGsVhjY7MGe8aMITTsLjHGEFrMmsCYCHZgtCBgYRe0oLUJs1xeGQswY9loGgOWQS1LLaktySq1+qjqo7ruK8/3ffaPNzMrqyrPyqOqOp9PREXn8eb7Ppmd+X1/73OKqmIYhmFc+zhbbYBhGIbRGkzwDcMw2gQTfMMwjDbBBN8wDKNNMME3DMNoE0JbbUA5Orr6tWdwz1abYWwTUr5HtMdntBMctbWKYRTjuRfGplR1pNhz21rwewb38IFPPLbVZhjbhIvLCxx+5zKfeSt0Jzu32hzD2JY4A+89V/K5VhpiGIZhbB0m+IZhGG2CCb5hGEabYIJvGIbRJpjgG4ZhtAkm+MaOYuxElE8/qyxFV7baFMPYcZjgGzuGfV297O8eZOxEjE8/a11eDaNWTPCNHYcj27p8xDC2LSb4hmEYbYIJvmEYRptggm8YhtEmmOAbhmG0CSb4hmEYbYIJvrEjGTsR48TSwlabYRg7ChN8Y8exr6sXR0I8+niXib5h1IAJvrEj2dfVC8hWm2EYOwoTfMMwjDbBBN8wDKNNaIjgi8jjIjIpIi+XeP64iMyLyAvZv19qxHENwzCM6mlUU5LPAr8L/HGZbf5RVf/7Bh3PMAzDqJGGrPBV9evATCP2ZRiGYTSHVvrw7xeRUyLydyJyWwuPa1zD/PUZ13rjG0aVtErwvwVcp6p3Av8H8FelNhSRh0TkpIicjC/Ptcg8Yyeyv3uAsRMdfPiRqIm+YVRBSwRfVRdUdSl7+8tAWESGS2z7mKoeU9VjHV39rTDP2MHs7x7YahMMY8fQEsEXkT0iItnb92WPO92KYxuGYRgBDcnSEZE/BY4DwyIyDnwaCAOo6u8DHwD+RxHJAHHgQ6pqM+oMwzBaSEMEX1V/tMLzv0uQtmkYhmFsEVZpaxiG0SaY4BuGYbQJJvjGNcGnn7WQkGFUwgTf2PE4EmLsRIyfe3HZ8vENowwm+MaOJzcQxfrjG0Z5TPANwzDaBBN8wzCMNsEE3zAMo00wwTcMw2gTTPANwzDaBBN8wzCMNsEE3zAMo00wwTeuCfZ19TJ2IsaHH4lyYmlhq80xjG2JCb5xzRAMQ7HiK8MohQm+YRhGm2CCbxiG0SaY4BuGYbQJJviGYRhtggm+YRhGm2CCbxiG0SY0RPBF5HERmRSRl0s8LyLyOyIyJiIvisg9jTiuYazHEZdHH++yYSiGUYRGrfA/C7y7zPM/CBzN/j0E/F8NOq5hrGFfVy/7uwcZO9HByenMVptjGNuKhgi+qn4dmCmzyYPAH2vAN4F+EdnbiGMbhmEY1dEqH/4ocKHg/nj2sQ2IyEMiclJETsaX51pinGEYRjuw7YK2qvqYqh5T1WMdXf1bbY6xw1Bf0bQHqlttimFsO0ItOs4EcKDg/v7sY4bRENTzSY3NkJlcBqAvJLz5nHL8nVtsmGFsI1q1wn8S+PfZbJ23AfOqeqlFxza2OaqKv5LGj6fRTa7ME6evBmKvgIKTVv7p8/DCC+nGGmsYO5iGrPBF5E+B48CwiIwDnwbCAKr6+8CXgfcAY8AK8B8acVxj5+PNJUi+NoWmfQAk4hK9eRi3N1r1PvzlFP5CMhD7wn2n4QtfiHPXXeFGmmwYO5aGCL6q/miF5xX4nxtxLOPawY+nSbw8Cf6qUmsiQ+KlK3Qc24cTre7r6S+nS3ZFHr/kN8JUw7gm2HZBW6N9SF9cLB5c9ZXMpaWq9yOx0IbVfQ6nCyvAMowsJvjGluEvp4sLtQZummpxeiKB6K/fjQOx+9w6LDSMawsTfKNpqK9kJpdJvDxJ4vQkmemVNUFZpztS3BUj4PRU78MXEWJv2YXTEwFHwBVwhOSuGLG32FfcMHK0Ki3TaDPUVxIvXsFfSuV99N5sAne4k+hNQ4gI4dEeMpcWwVu3zHeE8J7umo7nREN03L03yPRJ+zidYWYT84jEG/WWDGPHY8sfoylkJpfXiD0AvuJNreDPJ4FApGN37EY6w8FKX0C6wnTcuQeJbM4V43SEcXujTCTmAeWHDnt0Jzvrf0OGcQ1gK3yjYWjKI315CX8xuVHsc/hK5uoybn8MALcnSuexffgpL9D8TQp9MT7xsWWOd/c2bH+GsdMxwTcagr+cIv7C5SAIW0zoC5GNjnunQUJ/cXkBX4MumceGQpBsyG4N45rABN9oCInXpjb64ovhCKFdXU2xYXxpFlCOHE/wG3d0gblyDGMNJvhG3WjaQ5eraGHgCKHdXTVV0VbLxeUFQPmTh5N0J5tzQjGMnY4JvtFcBNz+GBJxCe3uxulrvNgD+JrhyPEEJUtuW0XIDf58hXS2ziAcglg2ZdTzIZ71M4WzP7+MF/wZRpMxwTfqRsIu0hkuusqXsEv09l1IEb99I8j57I8cT/CZt8rWZuR0d4DrICJBvUFHBFIZiIRW33/IRbs71r4uGoa0ByuJ1ttstBUm+EZDiN40TOLU5WBlq2TTLIXozcNNE/uczz6fjbOVAdpYJC/2QP5fLRT7LMU+Dw27wYo/XeNYRschKE3WIBgezga/bSaAUQQTfKMhuN0ROo7tI31xEX8xhdMVJryvB6ejuZ0qt03qZSRc14lNRNBouLTgF7qFNHtSdQqOp7o2+6kDSKQgae2hjVVM8I2yqCr+XIL0lWXwldBIJ+5wZ1Fxc6IhotcPNN2mbZF6GcqupHO+90ZcxLgO9HUFIp0o6CUUCUFHdPUzL3ZiKXbVEIsE9nklOoYKEIsG+4dg23iyclqtsWMxwTfKkno9O0Uq1x5hJo5zcZHYW3YjTusDpFueehlyoTO2VuA9HzwfLXDp5CjqvlEt+njeDRQNByv23Oo8Ft381UMkBPESjei6O8GR1eOGXOjphIUVcwddo5jgGyXxFpJrxB4AX/EXU2Qml2vud1MvW556KQJdsY3iG3JrntRVSvSDw0iwOk+mg2NuUutFBJUS3VPCoTVin99eNQgiJ6rvVmrsHEzwjZJkri6Xbo9weRFxBXzFGehoWKVsOVqWeulkG/v461whnaVTSvNiWS3JdLCiLnJVkMd1SrtjqiCwJ2tTNByIvGoQJygRcxCRwC7jmsQE3yhNGQHzF1Ikl6ezd5TwwT4i1/U3xYyWpV66TuCuybmqlCBV0nUgEt6wIl5PNW4XzQVcE6m8b77UvrQjCktxSKXRCkHhYlcMefHuKeK6KWufuXOuVUzwjdI4FZqpFrRSSJ+bR8IO4X2NzZhpeupldpWNr9C5zlcuoF1Bk7dqfejlXDX5K4BEMgjOVnqNm/384ykQJ0jdrJWsS2i966Ys5s65ZjHBN0rizddWCJQamw3aEw90VN64BhqeeplbwXfFQJyKHqJaxD737/rX5MV+cQV6imc5baDQnbaSCOx2nEDEIyFw3aq8W1VfeUAg9nW4kYztTUP64YvIu0XkNREZE5FPFnn+x0Xkqoi8kP37yUYc12gsmvLwFpJoKkg13IynPPnadM0BzGJcXF5gfGkG0CD1shGEXejtClwcPZ3gOEjW1ZH7W09NYp/xSq6ORYJ4ByG35PzdDftLrtuXr6tpoCF3je3516zfR5Uplvn3GamxbsJ1sicfG62xE6j7lyQiLvB7wL8BxoFnReRJVf32uk3/XFV/ut7jGY1HfSX56hTe9EqwivQVd7gT3YQHQTM+msggdRRcNSX1MuufrzW9saKLRhUyftA3J+2t9scpRq4atoQJef++EGTopEoUYcUixf31qqivwetzPXtcB+2oLq1TRFCH4MSYrtDbRwhaSRS6/TwfluNVndCMraERS6f7gDFVPQMgIn8GPAisF3xjm5L6znQg9kreL+9dXdncznxFN5lEU1hQ1fDUy1ikYbtS1UDcUkVEOZ0BjW4Q9fyKvcTVj+ayZ1IZ8LyyoimlVtO5IHNhIzbPh3CoaKC25EnAcYAKgt8ZC66QCvahuaD3svUE2q404jpsFLhQcH88+9h6flhEXhSRL4jIgVI7E5GHROSkiJyML881wDyjHJrxg/TLRq7KUpvzAfvqceR4gi/9J7fxmTjl0h/LUOguyf2RSGWzZ0qswJfjqO+vfU08tVr1mvHWuF/yK/vcNhX+L3R9umjeWIq7cOLJ4OSU8YIrh+V4cGLerOtNJHApFSsyC1UXVzC2hlY53v4aOKSqdwBfBT5XakNVfUxVj6nqsY6u5qT5Gatoylvbk6VehGC84Sb5ocNNahPs+fXHFpLpoAq1Un8azw+2W4oHq9355UBwcywnIJFCPT9wwaQzsFRDdWsiXdxf7/kbawei4SBeEQkHYhwNQ1dHyf9zESnuloqEobczyC7qjpW3r0nN8oz6aYRLZwIoXLHvzz6WR1WnC+7+IfBfGnBcowFItLogYtU4Euxzq3EkeF85Ycx4q/1vNoOSddfU8GGVy3ZJpjff2CyVBifbbC3n888Uaa/sOkX9/RVxs5lLubcai0C0oA7ALVNZXM2IS2PLaITgPwscFZHrCYT+Q8CPFW4gIntV9VL27nuBVxpwXKMBiOsQGu0hM7HYmB+qI7iDm03LbMDxQ25QEZsTp1wQE1lTDVtrEROwvdIVE6ngL1dDUEyAI3X8vHO7E9aKfe7h7Ge5xoevGtQYGNuWugVfVTMi8tPAVwAXeFxVT4vIrwAnVfVJ4D+JyHuBDDAD/Hi9xzUaR+RQP+II6fGFQDwcAVfK++IFJBZCE5n8aloiLrFNDDsprKStq/uls7HXjWadlhv61FdYqefELL9dfJsGIsudhEqkmpYj7xrK4Za/KlLPC4K8nh+cgGxy17amIQnOqvpl4MvrHvulgtu/APxCI45lNI5c6+PMXAIn7NJxbF/QATPkkHpjlsylxY2LbkdwhjqCxzMe7q5O3K4oEnVxujfhPiAI1jakkja6MRW0rD250YK+v1rElM4GViPZzBbfD1wv665+dOkSmiptrDN4aJNvooGkM2h44wCW9aw5uamudQ2VChDnWE6s/WwcybehIOOVDmwbW4JV2rYp6iuJF68EAdac2+PsHJGbhwgPdxHe30vm8lJRV4E/tZI/EfgLKbzQMh337G3aZKuqcB2oQtxyiEiQRphLIVyfd17Jx55OMfWrTzExd3jDU7e9f5HQ/dUaXtlOGbhucy/OnrwK2zYXdcNkvCB47Pmrc3jzG1Q4Rk8nrCSD+EY42zo6a7fmhrYsxq0/zzbBBL9NSZ+fx19KQm4Blw1wpl6dJvS2DpxYiNgdu0l+ZxqNB8LndIXxl9aJoK9o2iN1bo7o0aHWvYFIVkxEVgOXNdOcE9TpJ3rgibGG7OvOR46gM2c3+tCrPQksxSESRiOhfEGWuu7q5KxEqvwqvEwhWf4k0hmFhcyGwjYRCc4XHZHgpGBsOSb4bUrm8tKq2Bci4E2vENrdjdsbpfPYviB1UyAzHSc1NrMxuKuQubrSOsGPhtdmn5TR7VJB2nwrhG3OqYfHGO0/s+ax4U89sPEkEI4g3XuL7ySVXpsWWgvVnhOjkaIn3vxKf0sHDhs5TPDbFC2VkaOrz6kq/kISfzEFYad8oLOV3pwqUw3z9qoGWrQ+YLvJjBJdutSQfkHVst5tNFHuJBCJlhb+zdCok2LIBbJuI/PubBkm+G1KaLAjmGZVBHegA/V8Ei9PBmKvWtAjvsivVSC0q0UTqGpo0pUXeAhE3/NXg4mJ1KbSUHPB2swzzxf137eKYieBIHZwN8ye27zffz2eD6kMGqkQHylRYZs/MXYVFGul0qXHLhpNxVrctSnhQ/0QWtca2BFCe7txYiFS5+bxF7IDrXM9drwizb8cQWKhTQ0/2VRHzE2ItIgEducqZVfqG9Sdeeb5wE+/zTj9RA9Tv/pUcGU2c7ZxO44nYSWJZltCrL+6EZGiJ+JCd9qajqSRcNGMKqP52Aq/TXFiITru3Ut6fAFvJo6EXcKjPbjDQQ+bIEOnyAsFIocH8OMZNOXhDnQQ2tW16YHmR44n+cxbqb53TjZPvNjA8Iq4DmzSlb1TmJg7zMTDY9z5yJHG7jidyWbihIqOeiw3n7fYY/mZvUZLMcFvY5xoiOgNg3BDkSfLFPRIyCV6Q2MnW1WN62y6Edq2qpRtMplnnid0P4336edaLjRo8IrRWsylY2xAU2U6NvqK01d6mHfTqafNcaUiogpUKraqlnQizdSZaSZfnyK+0JwK3px7h3SDfeVprzEBesvL3xJshW9sIH1xseRzTl8MfymFN5fA7Y3i1DHoZFO4G9vyQvlBJYWv3ewqPyf2pYqtCvHSHiuzcdywS0d/EKxUX4nPJZi7NM/0GzN5my+/Igzs72P/3aNNWRGramODuNncfd1MU7ZCm2xu7pZggm9soNwsW38uQXIxmb8CCI10ErlxaNMtFWqumtLi21c8vgJa3wq/msycK69OcuW1q4gjq+mtZQLE6ilz4/P07Oqhf39fXfatZ2LuMPzqUwx/6gFYutQ4104yHcRRouGgj45TuWfPmkBvPGktF7YIE3wDCH6Q3tQK3kwcrTTezlv98WauriA9ESL7avPpjy/NcOR4gs+8VWobdpJMVRzZV7R9gBAUB3Vmu0smK1SY1kgmmeHsv55neSqYFFZO5Nfje8qV1yZBoHOgg0hn46ZzTcwdpv+Z5wm//Z6G7RNY7UMEEA0HQdjsubjkAPd0BhLpul1rxuYxwTdQzyf+wmV0JV3ad18KX8lMLNYs+EDtYg+BSGdH9pXLDCkU/fx2uX74rqAd0SAAXGM+eDqRZuqNaZauLuOGHcR1SCczJGbjdbmlEwtJzj83jvpK93AXh77rIG64MXMFTj/Rw218i9D92vggLqz2HXId6Iyi60Yf5ushwqEgy2cp3lYB9O2EBW3bHFUl8e2r6PImxD63j3SLf7xVtP2t6vlIuKbpTItX0rz2tdeZfH2Kldk4i5PLLFxaJD5Tn9jnUC+oeVi6uszpL7/K3MR8/TvNcvqJHjLPPN+w/RXF8wMxT2dK5uuLCHRsYdC/zTHBb3PSE4v4s/Vliri9Lf4BNyq2qdRUufvc52fx0q1pDaC+cu7kBRYuL5BONC5fXVNJdPZcw/a38QAEhW3lBpnX8JkbjcVcOm2MqpI+V+egeEeIXN/i2cOpDBorn4tfVdaOUFV6YC5D5+KpeI2G1okPb37zPCJCR1+Mg2/dz8pMnKuvT5FJZega7mLPzbuIdld3wj39RA+jTz/FyC/+QJMNp75xkkbTMMFvM9TzA5eII+Xz7avFobFD0KshmQ5a/jrlKzzLib6qBsHbanzJ6RTP/tjfbk3TLw1sXZmN8+pTryOuBK4fYG58noVLixx952FivRUGi2eZmDvMcKNTNYtRJsaCn+1p5GYHzJg/v2XYtVWb4C0kWXnuIivfuMDKP58n8fJkZQFzQXoj5V0oGSXxylQjTa2OxRWIp4r6inOUFXsFlqtbsafjaV59dnu0AdCCDCkU/IzPxZcv17SPUw+Pkf7Gt5rs2in+f5L/v+rpDFo0dHcEt60qtyWY4LcB/kqaxItXVgOzCt5MnMSLV3B3dZb+FnigC6nAbXPHrpL71+UUfnIL8qpTaajGdVOMlURVDdRUlS9/8OsNKwx1Iy4DB/u57rsOEGtQ7GN5amPXU/WV1HIKr0SK7dzTVxty7JKk0qVbSGezePJBXEegu7orFKM+zKXTBqTOzxcVN017uP0d4AU5+DiyJsc+j6dkzs0HzxcTSSnxeCvwdXPLlvW54LkeMeuY/OZF5l5dwO3vIPOO25l3O5k/swDxFD0LswxcvYTkXijgOA6hWAg3HHQiTS6lUE8JRV2Gbxhm+IZBHCcwONoVZewfzuD79QWCpSAIqqpcHZvmyquT+SuZvtFe9t81ihtq4fou7QWiH6k8Z1hEUMcJirgsR7+pNETwReTdwG8DLvCHqvpr656PAn8M3AtMA/+Dqp5txLGNyviLJfq/eIq/nCJ2ywh+MkPm8hLpC/NFJ2H5C0kk7AZ+/3VIyEFiW7R2SKTQrljtq/yezsDtkPHWjvFLpNZ0cUz7wl3f+AS/9xuzq21pDkPgXIdQKsHd//xf2dPpcfgdh2oyoaMvxo3vuoHLr02yPLVCKBYKZg2XqXQuRvfI6iyC6bOzXH7lyhrXz/zEAl7K4/DbV+2bmDtM/zeamJsPQY1DKrMawE1ngs+9GEp2QdF4M4xV6j7li4gL/B7wg8CtwI+KyK3rNvsJYFZVjwCPAr9e73GN6nFKibEj+eecaAinJ1ral+oIkRuHNgZoHSFydHATbhXhw49E+bkXiw9hqZqMB8l03pdfzSSqvDvBWR18nncvxCKBKPV2QV8Xnfcd5nf/99kiPciCHvuZSIxn3/VvOXfPd+Fp7a6laE+U644d4NZ338SNx28o6YIpR+F7vvLq5Fo/P4F7Z+nqMsnltW+iZbn5ucIsX0tfCQrgbf+RkzudRlzj3QeMqeoZVU0BfwY8uG6bB4HPZW9/Afg+sd6pLSN8oK94Jo1AqGB16PaX8KNmJ1qFBjuI3bkbd7gD6QjhDgX3Q0M1VssC+7sHcCTE2IkYD/6Ox1J0peZ9BEY7EA2vFe0aKOZewAmymESEf3p6Ba9ceCI7XOXFyH7+wL+TpFffTyrWU7tff/HKEueevUB8Pk4mUdxYcSTogVSEpufmFxJPbjgpq2o2HtMaE9qZRlyHjwIXCu6PA99VahtVzYjIPDAEbEjvEJGHgIcAugd2N8A8w+2PETkyQOqN2eABBQk7RG/bhRT4dcURYreOkDidDej5ujrR6vqBYF89UdxbSwdwa2FfV9COYXxplpPTGY53b2IndXRtLEXh/mamvSoDtkKaEL/PPeCB48LorXDs/XD/7/5F1eMQd9+0i8UrSzXZq54yNzHPwqUF3LATFIet38ZXol0be/TkcvMb3mCtFBkPlhNB7x3XyXbfrGPIulET2y5oq6qPAY8B7Dpws53zG0R4Tw+hXd2BP991cLrCRYXSHeig87tGyUwu46c83N4o7mBH04dZPPp4F3xsgePdNfbkcZtb4HPjrRG+/vfL+DV6G3wPzr8E50/DZ2/5D/zxbwciHv3SibLjEbuGOhm9Yy8TL16q7YAaNGELR1x8X9e4dUSErsFOoiWuHprWYK0UuZnCuW6brlM6IcBoKI1w6UwABwru788+VnQbEQkBfQTBW6OFiCO4fTHc7vKr4mDcYS/R6wcIDXU2Xez3dw8AwqOPd/FzLy7X5t5p8iCN+97RycDg5n4mAogPsctJPvKbvXzkN3v54Bvv5cjn7i37uuEbhrj5gaN0bcJVlo5nGDkyjLiCE3IQR+jZ3c2htx0s+7rTT/Q0Pzc/RzQMXTEkHAoyjCKhIG5iLReaTiM+4WeBoyJyvYhEgA8BT67b5kngo9nbHwCe1mqia0bbsL97gP3dg4ydiPHpZ7V60U+mKgZq6/mqhcPCZ35jN3e9dfN54tHpDCOXYfiCR3QyxUce6eGX73wXt72/9KCZaFcUZ5MCuOeWXdz+nls48s7D3Prum7j+/uuq6rw59/TVIPC9VOPVRS0IG9xwqwFza6rWbOoWfFXNAD8NfAV4BfgLVT0tIr8iIu/NbvZHwJCIjAE/C3yy3uMarUUzPqmJBRKvXCV1dg6/RHDQW0ySvryEN5fYlNDmArlVk8qUzdJpxLqip9flZ/7XYT77xf2868PDm2relrm4iHd1hc6LKQa+vYKT9Cuu9pNLmxunuDy7AgIrMyucf26cc89eYKlIcdZ6JuYOk3nm+eYGcV23dHC2lXUCbYps54X2rgM36wc+8dhWm9H2+IkM8ecvBSl2PllfhRC7bQQIRiJqysNPeZDygswVVQi7xG4bwV8MKnHdnijuUOV4wPjSLKAcOZ7gN+7oKrttHiEQk5AbuAhyNuQGbnREAn9xuV0UGdyhCuOTwgtvwIlvCYm0E+TKvzGDf6m24GohzkCM6evDfP5nFxj76HNFt3nzm+dYuFT6KqAcoWgIL+PlffniCsM3DLHvtj0VXzvaf4aRX/yB5vTacR3oLv4dUFWYrzNN18AZeO9zqnqs2HPbLmhrbD+Sr09DYeaHAqpBNk+xQFtuEZHySDx/OV/FmnEEibp03LUHKeNi2N89wMXlhSBl84THnzycrDwoRVmdwlRsXuriur45YXd1xm06w2kvxYjbz0ifoL4wvwzPvy48/S2H2cV1qZuOEDsySBLwNin6/mwCDoX4yG/2cuTj9/Pzn/uTDZk8u2/exeLk0oa8+mrIrGt1oZ4yNTbN0MGBksHbluD5wfej2FQsG3vYdEzwjbKor6X75VebVZHbzFc0kSH5xiyxm4fLvqQwZfPDj0Q5cjxY+f3QYa/2TJ5ipD1+7rmF/N2xEzEciXOwtyc7ua/yAJXY0SHSgx2kTm+uL81o1yDiCGMnZhj+1ANMPDy25vnO/g6uf9t1jD8/QWql/rRFRZm/tMCunpHK2zazo+ZyAu3uWPuY70Nicy4so3pM8I3WouBdXUZvqm7weW61f+YfuvHV49ETyl9vUvyXoit8+tng7BPECWI4EsoeJ9hPpsb0y/BQJ6mQQKa2VbjTG0WqaCvds6ubmx+4kRf/6nRthhVBstXBlWja8PMcsaAeID/6MNe9dPt6l68ZTPCNsogjOH1R/PkGrr5q/GHnVvtAXvwBHj2R4VE8PvGxtX7fwpPAUnSFk9OBq+DR3wniAY6EcGTtfushcmSI1Ks1tIh2IHrj0JqHHh4f4ef7nypaoCUihDvCpOP1r/L79pauASgkl5sfuv/uhg0YAwJX2rpe+SKCukGbC9Lm1mkmJvhGRaJHh4h/62LDGltJz+arY9eL9PjSLI8+XliiG1wB/NBhj78+4+ZX8gCOuA0T+UJCI51kpjvxr1aXSho7Nrqmv1GQjjrDr3/0w0V9+QC7bx5h/FRt/weFw1LEFXbfOFL1dCzIDT9/ntD94Aweqv7A5cj2LtSSPH0AAB2FSURBVNpgqwgaMcFvNib4RkWczjDSEQ766TeAyJHBoo97i0n8pRQSDeEOVNcBMyjaWsvYiVkePRHcbpbIF5Iam6la7AH8mTjuvrUr7ZxrqRSD1w3gpT0uvXyl6uMcuGeU+YsLhMIug4cG6ByovZDr9BM93Hl/MOaxIa6dbOps0f/bbZwxeK1ggm9URFMeWmXQUKIudIbREoFepy9KaF2WiHo+iZcm8Zey2TUStFyO3bEbp2NjP/VKFDsJNBJVJXNlmczFRTTtocnaHP+pN2ZwhzpwotX//ESEXUdHmPzOFF6RFtXrCUVDDOzvZ2B//fOGM1nXTkOCuKkMFOmRb1k6rcEqHYyKVF2rEXLouHsvnW/ZTeSW4bUdOh2BkLPBdw2QemM26PGTa5/rKZr0SLw82ZDCqUaTfHUqWNUvpWoW+xzeVHVXBOlEhqtvBANNlqeXizZAK8bw4eJXUZvh9BM9TP3qU43ZWbZdcmGhXL5bZq0Rc6NmbIVvVEQiLhILofEyKzBHiN44hESC/PrwSBduZzgoykpkIOziLySJP3sRQg7h/b2E9vfgzyfJXFkqGsjVZHBlIVWKXCvIzCfwanDflKSK89jcxDznT44Hm/uK8x0h2hNd45svioDThKpVVUVnztbvz0+kAl99bvBMOmODzFuECb5REZFAzBMvTW7Mvc8u4kP7enCH1uZWO10RokeHSF9dJvXa9OprMz7pc3Okz80FK/9S2iVBla+3mMKfTyCxEKE93TW5Qtajqvm2z5rySE8sBvuOBg3j3L7Vtg7qKxpPQ8hBUx6Zy0tkrjSgElTAHewou0kmmeH8c+Nowefte0piMUnvnh7mJxZKv1hh/tIiI0fK1zrUwsTcYSYeHuO29y8SfmcDJmR5PnhFCuSMpmKCb1SF2xej4969pMcXgsBqZzgI5oYc3IGOfNaJt5AkfX4efyWN0xUmfLCP9JtzG08UubvlVqqeklxX1JQ+P0/0tl2EKgjmelSV9PgC6QsLgdjk2vHmDr8I3lQc6YkQua4fP5EO7Ia12zWA0J4enM7ysYn5SwtFx+yqF4xAdFwHv8yq2A2bt9bYiAm+UTVOR5jo0Y0++BzrV/JeIoM3m2hsn3OF5OlJ3HccrKpwKW/b+flA7HO2lDjR6GKK5OnJzQt8iWHoecIO4cOVA6l+xi+ZtOJlfDqHO1gqc7UxdKh5gWtNJRubm2+0DFsGGA1BVUm9PrNR3Jsx1ELBm41X3o4gAyh9dZn0+fnaW0HUggOxt+6j4959hG8qEzD1tGR669iJWFDdSlBhW1RVJXgu0lE+rtE5WHsKZjXk5uD6M2eb20bZaAom+EZD0JV0eUFt8JIwn8JZhtTlRVa+cSG46mh2so+Cv5zC6QwT3lVmVqOAFhlBmKsVeN/nDzD328eI9cboH+3DcWXNa8UR5sbnmTk3W/oQDlX1v98sLRl+bjQFc+kYjaHcsA4BZ7ADfybeMOGV6FpBy+XGp8cX0GRmrcumFamdCqlXp3GPRXFiIaQzXLx2wVfc7uKr8/3dg9nW0AEH7hmle6SLqTdm8NIeXcOdzF2YXxPILUakO9r0KWUQuHaa1mDNaAom+G3E+NIskeUVjv7zc+x75Q28cIiz99zOm2+9HXVdHAltuirViYWQjlBRd4XTGyV24xAr/zpRPkhbw1zT1NgMmUtLRG8ZwYmFSH1nmszVla2di6pKZnKJyMF+IocHSH57XftoRwjt7c6nrq5nfGlmzX0RYfDgAIMHA3/8xMuXKoo9QFeT3DmF5Iafj/ziDzT9WEbjMMG/hlgvGOuJrMT54T/5f0leXkGzXoW7v/p1vu/Ff6LzmX/Hb/8/vYwvzbC/e3NFO7FbRoifuhyIuq/gCuI6RG8aJl0i136NfUcHi8cBiuGDv5giceoy0dt3NU/sKwVhC1HyhVihwQ7k9l2k3pzFX04jYYfQgV7CRZqXXVxewNegxuEvb3iS0x/fuM3y9ApTY5XHQIsr+RNEs5mYO8xwo3LzjZZggr9DKBSFcnzxIxdK+ldf/P/mOH05nhd7AN+DmStK34f/gS9+9i7e9/kDjC/NbGq173SG6bxvFG9qBT+ewekM4w53Io4EK/9yguwKTlckEP3Xqp9vrxmfzMXNTYWqiCNEb98VZO1UM4TEFdz+1Tx+tz9Gx93l89VzJ+mf+dgi/R8/yelTG8V+ZTbOmX9+s+KJx3GFgYMDmxp+vllO5XLz3y4bXTuuE0wZ8/yg372x5ZjgbzPKrdJ/5mOLvDM1V/L5Uw+PceoUQPEWuGNPXy7qEvA9ZfHKEqceHuOXGWPut4/xW4/3FNgiVfenEdchtHtj0FK6I1BuFe4p6YuLREZ7CO3rIXNpsbqVta+bmghVDRJycPui1Ym9EDR9q1Jsq1nVAyxcWeTsN8+Xd+UI9O/vY+jQYEvFPsfc01cZvl9Xe+eLQHfHalGdELRNWC4xSMdoGSb4LST4kZfrFxL8qD//sxurKLsm5zn18TFO1XH8kpkbDjgFhTr9Hz/JFx85wvKuPgA+8pv1uXoAwru7SZ8rnxrpXV4iPrlMaF83TlcEv1LmDwR+8eGOqnrTOP0x/LQH1XT9dITI0UFEBKc7UjoryAEch9CuLiKH+svWBqwGZIP3VG5Vn0lmmLkwy+VvT1YU+8PvOETPSJnMoCZT2DufpUvInsPgSBA4zn4cGnKDucJxq67dSuoSfBEZBP4cOAScBX5EVTfki4mIB7yUvXteVd9bz3G3KxeXS5e751ZzP/Ox8u6H/o+fZOyjDTUrz9D1g6zMxTesiAXZ0FXxVMG4vb98/yK/cOABxk7MALKplsMScui4aw/JV67ilxNcX8lcXCJ252407ZN85WrZFbZEXNyhTqK3OuULpqIuHXfsxvd84t+4UPbqwR3uIHygDzfb1TNyw8DGthKOENrdVbYQrZBC1w3AO1NznPr4WNFtFy4v8ua/nKuq932kM0L3cJWD3ptIrnd++HveBq6zIUso6HcfNsHfYupd4X8S+HtV/TUR+WT2/s8X2S6uqnfVeaxtTe4HfeR46cvWR/ZfLfkjbwX9+/tYnFxibiJI7cv9KEfv2kekTIOy00/08BGe4cjn7uWXvxVsN3YiOIHVsup3OsN03LsPPxVU4KbPzxdvyOYrmcllojcM4l/fT/pMkdYMgPRF6bhlBBEhNNiBe/8B4i9eQdevxh3JC7PjOoQP9ZM+O1dU9GP37N2QNun2xYjdsTsIwC6lkLBLaLSH8L7K06OCVb1y5HgiGG7y8WC4SakrNS/jcfZfz1cl9uIK1913oCUpmNUw9/RVho+7iO8HA+KNbYfU035WRF4DjqvqJRHZC5xQ1ZuKbLekqjVfc+46cLN+4BOPbdq+RlPOv57/QReZVrTdiM8nWLyyiLgO/ft6CW+i5/ydjxzhfZ8/ALDpdM74C5fxF4qPTgzt7SZ6dCjogXNujvT4Yj5jRjrDxG4eLtqPJth+nvTFRcj4SGeYyOGBNb13VJX0hYU11bfSHSF6yzDuJj6L9az/nnz+ZxcY++hzVb12dnye8ecn8DPlFT8UDXHT9x0hVEcjuWbgdIS4449+ECe6UfDV82GxAZ1GjbI4A+99TlWPFXuuXsGfU9X+7G0BZnP3122XAV4AMsCvqepfldnnQ8BDAN0Du+/9d7/4F5u2rxZqyYIp1ht8Jwh9oxntP8Ppz/wIv/V44Uq3+gBv6uJC8dW7I8RuG8EdKBDpjI+/kkYi7prxgOUoOVkp97yvaNpDwm5NfXmKsV7kc9+TWr8X02dnGH/hYlmXkzhw0/ceJdpT/bjCVrL3R25m14NHcAv+n9T30avjkE42fii6sYa6BF9EvgbsKfLUp4DPFQq8iMyq6oZfu4iMquqEiBwGnga+T1XfqGR4I1f4uUvrcvzMxxZ5xz/8t5LPn36iugHQ7cZt7w/80skHj/OR3wxW+tW4etTzib9wOXDr5EQ/OzQ9dvuubeOqKMb6BcKR4wn+84VgITD39NWyQp9cTpFcTBLpihDLinZ8IcH0mRni83FWZkr3CRJHOHDPKAMH6p9k1UwG33WQPT98I+GBGMmJJZJf+ntSp88x/KkHECmSwmk0jGau8Kty6ax7zWeBv1HVL1Taf62CX2mV/vmfXaBrcr7k84WBSmNz3Pb+RT74RrmY/NorAPV80peX8CaXQYJK1NCurm0t9oUB2FyabDXfHT/jc+7ZCyxOLgW1Cap09ncwcKCfiZcuVZVe2jnUyZHvvr7uK5Kt5Lb3LxK6/24ksnqFYqv+xtFMwX8EmC4I2g6q6v+ybpsBYEVVkyIyDDwDPKiq3660//WCX9hnZCOrqW7H+je+p/jH/7It3S5bxZHP3Vv08dwVQC3d1Jo9o7Ya1qdU/tG9L/OP//E5VmbjRDrD7LpxhN495a8Azz83ztz4ul44tVTyArf/0C24oZ0fEB3tP0P/944ABOJvq/6G0UzBHwL+AjgInCNIy5wRkWPAT6nqT4rI24E/IMg7cIDfUtU/qmb//aNH9fhPPQpUl9b4ztScrdJbSDqRYfrsDIn5BLG+GEOHBglX8K/n/P7VkosPOFJ9cHKz/YDWk0uzXf/d2/tTf8q/fCW1ZkUurrD31t0lp0z5GZ+X/ubbdTePe8uDt+I411aT29H+M/m20BJpwDStNqdpgt9sdt98WD/82P+Wv79TsmDagZW5OG/845tB4NNXxBHEEW74766ns7+2aVTluC1bA1AtYyeC1gb1FImtT7H95XtSa7JsXvv710kUyS4SV7jtPbfgFsyT9T2fhSuLXP72FZKL9eWgR7oj3PJvbqxrH9uZnKsnh4n/5tixgn/rwG79/Pd+aKvNMIrw6le/Q7JI9Wm0O8LNWyhKhemi9fDFj1woerXoez4vPVncG+mEHK5/20G6s1Wvi1eXsm0R/DX9izbL7ptH2HPL7vp3tAPIrfrN1VM75QR/eyXxGjuC1EqKVLFe70ByKcWF58cZuWGYWG+s6DbNJNcPqFoKTxB/ecOT+UysUyUqo0SCK5mi7Q4UnGz7ikwyw9lnzuFX2YenGlfP4tVl9txSebtrgdzQ9DsfOYLOnM0/bl0568ME32g4M2fnmL0wz77b9zB8uLrWA+l4mqXpZdywS89Id8uyUE49PMb/3R/kyxfrabMecYS+fb3MTcxvEGk36tLRF5zk5sbnq5+7UuV28dk4mZRHqEQ//WuRwquswOWDrfrrwATfqJlwR5hwR4hUmZ446ikXX7pM375ewrHS1auqwXbTb87kRV5EGL1zL37Gx4249O7pwSk3UatOao0L9Y32Mn9xgbw7VIKWDde/7bp8Omk6ka5qWEktiCOk4+m2EvxCckNXhj/1ADpzNv9Zm/hXjwm+UTMiwsF7D3Dmn8/i+37JFaqqcvX1KbpHuukc7CQUcVFfmb+0QGIhQaQzgvrKzNmZfPA3x/mT40EXT8dBBK5/+6GWTHKqxMLlRc6fHF9jq4gwfHgwv7pfuLzI4pWlhh9bfSVSpJ1EO5Fz9Yz2nwFYFX8L8FaFBW2NTZNaSTH1xgxTZ6YrtvAFGL5hkPmLi3gpDz/j47gOvlddNNMNO9z6gzc3daVfDa889VrRKxtxhNveczOTr08xNTZV2Xcv2Q6SRT43N+Lie/6GtM/BgwPsv2tf3e/hWiNfyGWuHsCCtkaTiHRG2PeWPagq02emS/uss49Pja3tN1Ot2EMwh3zxyhJ9+xqTY78ZvIxfMlitvjJzfparr09V7cpxXMFbt624wt7bd5NaTjM1No1mP7yh6wfZd1uxDifG6Sd64ImxrPCvfp4W4N2ICb5RN7tvGmH+4gLpeBWDRTaJqpJJVW5uVw+z43Nc/vYkqZUUoWiI3TeN0D/aR2o5RbgjXLEz5aWXr1R9rL237aF7pIs3v3Euf+JTXxm+fpDBgwOICLtvGiGTzBCKhrb8ymYnkBN+KAjwmqtnDebSMRqCl/Z49Wuvk0k0T5SdkEPPrm723LJr0ymfmWQm6GUjQs/u7vwUsJlzs1x4YWJjH/psQFZ9pXu4C9/zWJ4u3dys2vdx+O3X0TXUhaqyPLWMl/bpHOysWKlsVE9hBS+0T3aPuXSMpuOGXboGO5m/WHrqV734GZ/5iwssXlnihu+5nlA0xNTYFMszcaLdEUaODOcDp8WYemOaiy9fzmcDqa/sv3sfAwf6ufjSpeJDR5R8b/qlqeXGpIsKdA4EAWgRyRdqGY0lF+CFVfFv9wCvCb7RMEaODrNwZbFpQ8Vz+J7P+PMXSS4lgywhH1ZmV5ibmOfgvfvpH+3b8JqVmRUunr68IRto/IWLRLsieOnK8YT1r90M4goH79m/o7td7kRy4p9v3zB7LngiHGkr8TfBNxpG12An++/cx8SpSyjaVOGPz61zq2iQ+3/h+Qn69vZuENSrZ2aK2qO+MjteumV2vYgjdI10oZ4GVyE3DG1JBbIRkMvlzzH8qQdg9lxbuHrABN9oMIPXDdC/v4/lmRWWp5a58urVml4vrrD/7n1ceG5ic50lFVZm43QNrc3ZzyRKBJQ18Os3D6V3V3fJLppG6ykstFtd9WtbuHos9G80HMd16BnpZs8tu+nd24NU8S0TVwhFQxy8Zz+DBwaC9MtSXo8K3pBi7pKeXcXbNYgr9O7u2XS6pxOS4CR3oK+4Xeaj3/acfqKHqV99Ck0l0Zyr5xrFVvhGUzl4z37OfOMsK7OlM1v6RnvZd/sewh3hfLn86J37WJmNk0lk1la1OtmApwPLUysbrgIc16Gjf6PLZOjQIFfHpoPUztxrHAhHQ/Tv76N3Tw+JhQSpeBr1dE2bh3L1At3D3Ry4Z5TUSorFy0t4GS+/f3GFvj09ZQPJxvZgrY+/4Pt2ja36LS3TaAkTL15i6sx0UYE+cM8o/fs3Blp9L8jKWZpaxst4xLqj9OzqoXOwg/RKmtf/4Q28jJ8X6FwLhu7hrqI2pONpLp2+wvylBUSgf7SPPbfuzufXq68sXF4kPh8n3BGmf7QPJ+Rw7tkLzE8Uzz7q3dvD9W8L/L+plRRXXrvK4pVF3LDL0OFBhg4NbutxjUZpdmoFr/XDN7YcL+3xnafHSMcz+aZj4gixnihHj9+wqawVL+0xe2GOldk40a4Ig4cGyjZq2yyLk0u8+c1zG4K+jiscPHZgS6t/jeayZhrXDmnWZnn4xpbjhl2OvusGJr8zxdz4PCJBgHfkyPCmUxTdsFt1++V66B7pon9fH/MX5/M9chzXoWd3N717K7dUNnYuhbn8QL4//0519dgK3zCqQFVZurrM7IU5UOg/0BcEgs1d03YUunoIRwC2lfjbCt8w6kRE6NnVTc8uy7hpdwqbtQGE7r8bnTm7I5q11ZWWKSIfFJHTIuKLSNEzSna7d4vIayIyJiKfrOeYhmEY24HTT/Rw+okeTj08RuaZ5/FnzqJLl7barLLUm4f/MvB+4OulNhARF/g94AeBW4EfFZFb6zyuYRjGtqEwl9+fORuI/zbM6a/LpaOqrwCV/Jj3AWOqeia77Z8BDwLfrufYhmEY24md0KytFZW2o8CFgvvj2ceKIiIPichJETk5m6yvDa1hGMZWMDF3OO/qWbPq32KXT8UVvoh8DSg2audTqvqlRhukqo8Bj0GQpdPo/RuGYbSKwqEs+Zz+LWzWVlHwVfX76zzGBHCg4P7+7GOGYRhtw/r2DXlXeAtbNLciLfNZ4KiIXE8g9B8CfqwFxzUMw9h2FLZo7v/ekXx//las+utNy3yfiIwD9wN/KyJfyT6+T0S+DKCqGeCnga8ArwB/oaqn6zPbMAxj5zIxd5iJucOr2T2qeR9/M/38VmlrGIaxDSgs5ILNd+q0SlvDMIxtzuknsn2ZnhhrWoDXBqAYhmFsM3JpnTlXT+6vXmyFbxiGsU05VdCpM8juoa7+/LbCNwzD2AFsCPDOnqu5fYOt8A3DMHYIuVz+0f4zADW3bzDBNwzD2GFMzB0O/s0XcgW5/Ln+/KUwwTcMw9jBrO/PXw4TfMMwjGuAfFpnGSxoaxiG0SaY4BuGYbQJJviGYRhtggm+YRhGm2CCbxiG0SaY4BuGYbQJJviGYRhtggm+YRhGm2CCbxiG0SaY4BuGYbQJJviGYRhtggm+YRhGm1CX4IvIB0XktIj4IlJ0aG52u7Mi8pKIvCAiJ+s5pmEYhrE56u2W+TLwfuAPqtj2Xao6VefxDMMwjE1Sl+Cr6isQzFg0DMMwtjet8uEr8JSIPCciD5XbUEQeEpGTInJyNhlvkXmGYRjXPhVX+CLyNWBPkac+papfqvI4362qEyKyC/iqiLyqql8vtqGqPgY8BnDrwG6tcv+GYRhGBSoKvqp+f70HUdWJ7L+TIvJF4D6gqOAbhmEYzaHpLh0R6RKRntxt4AGCYK9hGIbRQupNy3yfiIwD9wN/KyJfyT6+T0S+nN1sN/BPInIK+Ffgb1X1v9ZzXMMwDKN26s3S+SLwxSKPXwTek719BriznuMYhmEY9WOVtoZhGG2CCb5hGEabYIJvGIbRJpjgG4ZhtAkm+IZhGG2CCb5hGEabYIJvGIbRJpjgG4ZhtAkm+IZhGG2CCb5hGEabYIJvGIbRJpjgG4ZhtAkm+IZhGG2CCb5hGEabYIJvGIbRJojq9h0bKyJXgXNbbUcBw8DUVhtRJWZrczBbm8NOshW2t73XqepIsSe2teBvN0TkpKoe22o7qsFsbQ5ma3PYSbbCzrM3h7l0DMMw2gQTfMMwjDbBBL82HttqA2rAbG0OZmtz2Em2ws6zFzAfvmEYRttgK3zDMIw2wQTfMAyjTTDBL4OIfFBETouILyIlU7BE5KyIvCQiL4jIyVbaWGBDtba+W0ReE5ExEflkK20ssGFQRL4qIq9n/x0osZ2X/UxfEJEnW2xj2c9JRKIi8ufZ5/9FRA610r51tlSy9cdF5GrBZ/mTW2Fn1pbHRWRSRF4u8byIyO9k38uLInJPq20ssKWSrcdFZL7gc/2lVttYM6pqfyX+gFuAm4ATwLEy250Fhre7rYALvAEcBiLAKeDWLbD1vwCfzN7+JPDrJbZb2qLPsuLnBPxPwO9nb38I+PNtbOuPA7+7FfYVsfd7gHuAl0s8/x7g7wAB3gb8yza29TjwN1v9mdbyZyv8MqjqK6r62lbbUQ1V2nofMKaqZ1Q1BfwZ8GDzrdvAg8Dnsrc/B/zbLbChHNV8ToXv4QvA94mItNDGHNvl/7QqVPXrwEyZTR4E/lgDvgn0i8je1li3lips3XGY4DcGBZ4SkedE5KGtNqYMo8CFgvvj2cdazW5VvZS9fRnYXWK7mIicFJFvikgrTwrVfE75bVQ1A8wDQy2xroQdWUr9n/5w1kXyBRE50BrTNsV2+Y5Wy/0ickpE/k5EbttqYyoR2moDthoR+Rqwp8hTn1LVL1W5m+9W1QkR2QV8VUReza4OGkqDbG0J5WwtvKOqKiKlcoOvy36uh4GnReQlVX2j0ba2AX8N/KmqJkXkPxJcmXzvFtt0LfAtgu/okoi8B/gr4OgW21SWthd8Vf3+BuxjIvvvpIh8keAyu+GC3wBbJ4DC1d3+7GMNp5ytInJFRPaq6qXs5fpkiX3kPtczInICuJvAX91sqvmcctuMi0gI6AOmW2DbeiraqqqFdv0hQQxlu9Ky72i9qOpCwe0vi8j/KSLDqrpdm6qZS6deRKRLRHpyt4EHgKJR/W3As8BREbleRCIEwcaWZr9keRL4aPb2R4ENVyciMiAi0eztYeAdwLdbZF81n1Phe/gA8LRmI3ktpqKt63zg7wVeaaF9tfIk8O+z2TpvA+YL3H/bChHZk4vbiMh9BHq6FSf96tnqqPF2/gPeR+BDTAJXgK9kH98HfDl7+zBBZsQp4DSBe2Vb2pq9/x7gOwQr5a2ydQj4e+B14GvAYPbxY8AfZm+/HXgp+7m+BPxEi23c8DkBvwK8N3s7BvwlMAb8K3B4C7+nlWz9z9nv5ingvwE3b6GtfwpcAtLZ7+tPAD8F/FT2eQF+L/teXqJMdtw2sPWnCz7XbwJv3ypbq/2z1gqGYRhtgrl0DMMw2gQTfMMwjDbBBN8wDKNNMME3DMNoE0zwDcMw2gQTfMMwjDbBBN8wDKNN+P8BhB5WeHkwLZkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# create a 2D grid\n",
        "step = 0.02\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, step), np.arange(y_min, y_max, step))\n",
        "\n",
        "# predict for all the points in the grid\n",
        "\n",
        "y_hat = nn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "y_hat = y_hat.reshape(xx.shape)\n",
        "\n",
        "# plot\n",
        "fig = plt.figure()\n",
        "plt.contourf(xx, yy, y_hat, cmap=plt.cm.Spectral, alpha=0.8)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.show()"
      ]
    }
  ]
}